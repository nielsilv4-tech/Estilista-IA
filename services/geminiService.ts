import { GoogleGenAI, Modality } from "@google/genai";

/**
 * Generates a composite image by combining a person's photo, item images, and a text prompt.
 * @param personImage Base64 string of the person's image.
 * @param itemImages Array of Base64 strings for item images.
 * @param prompt Text prompt with editing instructions.
 * @returns A promise that resolves with the Base64 string of the generated image.
 */
export const generateCompositeImage = async (
  personImage: string,
  itemImages: string[],
  prompt: string
): Promise<string> => {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
  const personMimeType = 'image/jpeg'; // Assuming jpeg, adjust if needed

  const parts: any[] = [
    { inlineData: { mimeType: personMimeType, data: personImage } },
    ...itemImages.map((item) => ({
      inlineData: { mimeType: 'image/jpeg', data: item },
    })),
    {
      text: `Based on the first image of the person, realistically add or replace items from the subsequent images (clothing, objects) onto them. Also apply the following instructions: ${prompt}`,
    },
  ];

  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash-image',
    contents: { parts },
    config: {
      responseModalities: [Modality.IMAGE],
    },
  });

  const firstPart = response.candidates?.[0]?.content?.parts[0];
  if (firstPart && 'inlineData' in firstPart && firstPart.inlineData) {
    return firstPart.inlineData.data;
  }

  throw new Error('No image was generated by the API.');
};
